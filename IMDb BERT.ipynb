{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pItWuQqYBJms"
      },
      "source": [
        "## For this project, we will utilize 2 nlp packages that utilize bag of words (sklearn) and Word2Vector(spaCy) and various models to analyze the sentiments of imdb reviews.\n",
        "\n",
        "\n",
        "Note: to save runtime, when I'm testing one model, all other models will be commented out. If you want to test them out instead, just uncomment them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqCMveoSFndX",
        "outputId": "38d53853-23fe-4fe7-cd43-86a23f799b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w0PhBsWfyLj63YpT7wacP9eCJQXvIQKJ\n",
            "To: /content/IMDB Dataset.csv\n",
            "100% 66.2M/66.2M [00:03<00:00, 17.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "! gdown 1w0PhBsWfyLj63YpT7wacP9eCJQXvIQKJ;\n",
        "\n",
        "#this is the file we are working with. I made sure anyone can access it, so you should be able to run this code on your laptop too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFDQY5vTA3zs"
      },
      "outputs": [],
      "source": [
        "#this is just importing the libraries we will use\n",
        "import random;\n",
        "random.seed(100);# I am setting an arbitrary seed to the results will be the same everytime we run the code\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "import matplotlib.pyplot as plt;\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer;\n",
        "from sklearn import svm;\n",
        "from sklearn.metrics import classification_report\n",
        "#from sklearn import metrics #For Matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import tensorflow.random\n",
        "np.random.seed(100)\n",
        "tensorflow.random.set_seed(100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objects as go\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "nyKCw7mIoETx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3pCwUE2onIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1Ogi9rjF66Z"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"IMDB Dataset.csv\")#creates a pandas dataframe of the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nzkUEtzJ0CqA",
        "outputId": "9f4fa0b3-680e-48a2-dddd-7a789195e644"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a6748d4-2050-459e-a34a-585c88542131\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a6748d4-2050-459e-a34a-585c88542131')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a6748d4-2050-459e-a34a-585c88542131 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a6748d4-2050-459e-a34a-585c88542131');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2deedc0d-e080-4ea4-83e3-686f4f633d17\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2deedc0d-e080-4ea4-83e3-686f4f633d17')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2deedc0d-e080-4ea4-83e3-686f4f633d17 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()#checking the first 5 roles of the dataset. notice the <br /><br /> in row 1. I know it's an eyesore but I'll take care of it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6Vq3eazEjiQ"
      },
      "outputs": [],
      "source": [
        "df = df.sample(n = 30000, random_state = 100)\n",
        "#training a model with 50000 instances is just too long, I cut it down to 10000 because 2000 takes only 3s but 25000 takes 42 min, and 10000 only takes like 12s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Zm5c8J4QEncS",
        "outputId": "f13c2f11-1db4-4f61-d14a-cd63e7aae41b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "4253   This is a documentary about homeless women. It...  negative\n",
              "30076  Not well done at all, the whole movie was just...  negative\n",
              "48047  It's strange what fate does to some people. Wh...  negative\n",
              "1666   And that goes especially for lawyers & cops. P...  positive\n",
              "30740  First, an explanation: Despite my headline, I'...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6eba25d7-f6d8-4d41-8ec9-24639de8090d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4253</th>\n",
              "      <td>This is a documentary about homeless women. It...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30076</th>\n",
              "      <td>Not well done at all, the whole movie was just...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48047</th>\n",
              "      <td>It's strange what fate does to some people. Wh...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1666</th>\n",
              "      <td>And that goes especially for lawyers &amp; cops. P...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30740</th>\n",
              "      <td>First, an explanation: Despite my headline, I'...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6eba25d7-f6d8-4d41-8ec9-24639de8090d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6eba25d7-f6d8-4d41-8ec9-24639de8090d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6eba25d7-f6d8-4d41-8ec9-24639de8090d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dda68b54-3a35-4de4-a41f-75ec4b41a415\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dda68b54-3a35-4de4-a41f-75ec4b41a415')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dda68b54-3a35-4de4-a41f-75ec4b41a415 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29852,\n        \"samples\": [\n          \"Deepa Mehta's \\\"Fire\\\" is groundbreaking, bold, and artistic. A masterful social commentary on the plight of the women from conservative, upper middle class Indian households, this is a film no one should miss. Shabana Azmi and Nandita Das give stellar performances by underplaying their characters as much as possible. A.R. Rahman's music is the work of the genius and almost plays the role of another character in the film. Mehta uses Rahman's score and together, they create such amazing sound montages that effectively portray the views of the world around Radha and Sita whenever they look to each other for support. This film is not about lesbianism as many have branded it. Lesbianism is just a part of the film. It is unfortunate that most people tend to write the film off calling it taboo instead of giving it a chance and looking at its real meaning.\",\n          \"I posted on IMDb on this series recently, giving a snail mail address at the commercial arm of the BBD where one would write to appeal release. I wrote to that address, mentioning Sam Waterson and his popularity prominently. I just received the following reply: <br /><br />From: emilyfussell@hotmail.com Subject: Oppenheimer Date: May 14, 2006 1:44:00 PM MDT To: kk2840@earthlink.net <br /><br />Dear Kate, <br /><br />I work for the BBFC, the British equivalent to the MPAA, and we classify DVDs and videos as well as films in this country. Anyway, I am currently in the process of giving a certificate to the 1980 miniseries 'Oppenheimer.' While researching the work on the IMDb, I noticed your post and thought you might like to know that the work is about to be released (hence the need for a certificate). <br /><br />I don't know which company is distributing it, but keep your eyes peeled! <br /><br />Kind regards, <br /><br />Emily +++++++++++++++++ <br /><br />hooray! <br /><br />I also want to contact Netflix re purchasing this. <br /><br />Kate Killebrew <br /><br />kk2840@earthlink.net I emailed the BBC recently regarding whether their terrific series Oppenheimer had ever been released on video or DVD. I have not been able to find it. I received the following reply. If you do write the BBC, be sure to mention that Sam Waterston is very popular in the US. You can also enter \\\"Oppenheimer (1980)\\\" on amazon.com, and find a box to check to request release by the owner (BBC) and be notified when it's released. <br /><br />Kate Killebrew kk2840@earthlink.net<br /><br />Here's the reply from the BBC:<br /><br />Dear Kate<br /><br />Thank you for your e-mail regarding 'Oppenheimer'.<br /><br />I was interested to read that you would like a copy of this programme which you have enjoyed. I have checked the BBC Shop and on-line retailers and can find no record of it being available. We are unaware of plans at present to release this programme on DVD. However, if you would like to make a suggestion, can I suggest you put it in writing to the commercial arm of the BBC:<br /><br />Commissioning Editor BBC Worldwide Ltd Woodlands 80 Wood Lane London W12 0TT<br /><br />May I thank you again for taking the time to contact the BBC.<br /><br />Regards<br /><br />Elaine Hunter BBC Information ______________________________________<br /><br />-----Original Message-----<br /><br />{Comments:} i am trying to find a copy of the terrific BBC production \\\"Oppenheimer', a six part series made in 1980 with Sam Waterston from a book/script by Peter Prince. I watched parts of it then on PBS American Playhouse, but can't find it on video anywhere.<br /><br />http://www.bbc.co.uk/\",\n          \"This is an \\\"odysessy through time\\\" via computer animation, supposedly th work of over 300 artists. Made in the late '80s and released in 1990, this was cutting edge stuff for the day. I thought it was good and quite interesting in spots.<br /><br />Most of the short scenes made no sense, just forms evolving into other forms, but that was fun to watch. This is all about visuals, not really about any kind of a story. There were some strange sequences in which odd-looking men- creatures would dance around with birds overheard. All of it is computer animated which was new back then. Even the term \\\"computer animated\\\" was not well-known.<br /><br />It's simply a chance to show off this new technology in short bits of cartoon-like happenings with beautiful colors and imaginative scenes. No words, just pictures with electronic music. Stoners must have really loved this.<br /><br />It's a nice, intriguing 40 minutes of \\\"eye candy\\\" and \\\"head candy.\\\" By today's CG effects this may have lost impact, but I think you'd still be entertained by this.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFprorMsJ4Ec"
      },
      "outputs": [],
      "source": [
        "X = df[\"review\"]#creates a dataframe of the features(reviews)\n",
        "y = df[\"sentiment\"]#creates a dataframe of the labels(sentiment: positive or negative?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOUzVdQKokr6"
      },
      "outputs": [],
      "source": [
        "# X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwfJp43SFhbT"
      },
      "outputs": [],
      "source": [
        "# y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZRVSlDww8bi"
      },
      "outputs": [],
      "source": [
        "for i in X.index:# I noticed that a good portion of the reviews contain the \"line change\" symbols in HTML, i.e. <br /><br />\n",
        "  X[i] = X[i].replace(\"<br /><br />\", \"\")#I made this loop to delete all the line change symbols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7R9vpwuvMCQ"
      },
      "outputs": [],
      "source": [
        "# X.head()\n",
        "#notice the brbr thing is gone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH37jVK0yMfN"
      },
      "outputs": [],
      "source": [
        "y.replace(['negative', 'positive'], [0, 1], inplace=True)#for the labels, we need to change the strings \"negative\" and \"positive\" to 0 and 1, so the ML model recognizes it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "o3WebBxjzp8o",
        "outputId": "efc92048-0eaf-483d-f560-5d465358c003"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4253     0\n",
              "30076    0\n",
              "48047    0\n",
              "1666     1\n",
              "30740    1\n",
              "Name: sentiment, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4253</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30076</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48047</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1666</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30740</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "y.head()\n",
        "#notice the positive and negative get turned into 1 and 0."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "sYP66x8dO8hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiWZEsmiPoOX",
        "outputId": "c6c9c527-5ca6-465a-c653-f695af4671b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning:\n",
            "\n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckfRqbHFK34i"
      },
      "outputs": [],
      "source": [
        "# X = np.array(X)\n",
        "# y = np.array(y)#we are converting the dataframes to numpy arrays, because the machine learning models only accept numpy arrays as parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to0axQyGsi0q"
      },
      "outputs": [],
      "source": [
        "# vectorizer  = CountVectorizer();#creates a vectorizer object, which transforms the sentences into arrays(vectors) that document how many times each word appears\n",
        "# X_vectors = vectorizer.fit_transform(X)#transorms X into vectors. DO NOT PRINT IT OUT. IT'S TOO BIG AND THE SESSION WILL CRASH\n",
        "# #however, X_vectors can be directly used to train data and we don't need to conver it into a numpy array or anything. It's technically called a sparce matrix but you don't need to worry about the specifics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf0j1NmYtOzX"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 100);\n",
        "#splitting the data into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpBtaLAlDMBM"
      },
      "outputs": [],
      "source": [
        "# print(vectorizer.get_feature_names_out())#the feature names, i.e. what word corresponds to each place\n",
        "# #the features are the \"words\" the vectorizer extracted. i know the first few are a bunch of zeros and the last few are gibberish, but there are a ton of normal words in the middle.\n",
        "# #You can print them all out but its gonna be a LOOOOOOONG list and tbh idk where the arabic at the end came from (I couldn't find it in the original file) but I'll leave it there for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx6t88q85XfS"
      },
      "outputs": [],
      "source": [
        "# X_train_vectors = vectorizer.fit_transform(X_train);\n",
        "# X_test_vectors = vectorizer.transform(X_test);\n",
        "# #generating the vector version of the x train set so they can be used directly in training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdZxcbzoRMuU"
      },
      "source": [
        "##SVM (has great performance, has liek 82% accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHY2Kpuf7Yz1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# model = svm.SVC(kernel = \"linear\");#training a support vector machine(SVM) model just like the vid I showed you, I'll try others like KNN and Log Reg too.\n",
        "# model.fit(X_train_vectors, y_train);\n",
        "# from sklearn.metrics import classification_report\n",
        "# y_hat = model.predict(vectorizer.transform(X_test));\n",
        "# print(classification_report(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCzZtLaQREQe"
      },
      "source": [
        "##KNN(This has like 60% accuracy, it's horrible just ignore it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHRHZMHXGh5r"
      },
      "outputs": [],
      "source": [
        "# # #try KNN model. KNN performs significantly worse than svm. at the best (k = 75) it still 67% accurate\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# arr = [5, 10, 50, 75, 100, 200]\n",
        "# for i in arr:\n",
        "#   model = KNeighborsClassifier(n_neighbors = i, weights = \"distance\")\n",
        "#   model.fit(X_train_vectors, y_train)\n",
        "#   y_hat = model.predict(vectorizer.transform(X_test));\n",
        "#   print(\"i = \", i);\n",
        "#   print()\n",
        "#   print(classification_report(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm5vzjFZ17cj"
      },
      "outputs": [],
      "source": [
        "# # Test 2 with other method for CM.\n",
        "# # 0 = negative review; 1 = positive review\n",
        "# cm = confusion_matrix(y_test, y_hat)\n",
        "\n",
        "# cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = ['Negative review','Positive review'])\n",
        "\n",
        "# cm_disp.plot()\n",
        "\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uud3yx9Zm8yb"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix for KNN--Although it's accuracy is low.\n",
        "#I HAD issues on understanding the\n",
        "\n",
        "# actual = np.random.binomial(1, 0.1, size = 10000)\n",
        "# predicted = np.random.binomial(1, 0.1, size = 10000)\n",
        "\n",
        "# confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "\n",
        "# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix= confusion_matrix, display_labels=[0, 1])\n",
        "\n",
        "# cm_display.plot()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofi8qLoHR5rg"
      },
      "source": [
        "##Naive Bayes(Also horrible, has like 64% accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvEqLE0kGkez"
      },
      "outputs": [],
      "source": [
        "# #implement a naive bayes model\n",
        "# from sklearn.naive_bayes import GaussianNB;\n",
        "# model = GaussianNB();\n",
        "# model.fit(X_train_vectors.toarray(), y_train);\n",
        "# y_hat = model.predict(vectorizer.transform(X_test).toarray());\n",
        "# print(classification_report(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8oCAF6fS4b8"
      },
      "source": [
        "##Logistic regression(Has a 86% accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mItVHzBj8eG1"
      },
      "outputs": [],
      "source": [
        "# #implement a logistic regression model\n",
        "# from sklearn.linear_model import LogisticRegression;\n",
        "# model = LogisticRegression(max_iter = 200);\n",
        "# model.fit(X_train_vectors.toarray(), y_train);\n",
        "# y_hat = model.predict(vectorizer.transform(X_test).toarray());\n",
        "# print(classification_report(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GBlSdNoTMvE"
      },
      "source": [
        "##Neural Network: this is where the bulk of the effort is going to be put into. (The highest so far is 87% accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pDaB2oYPamj"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# !pip install -q opencv-python\n",
        "# !pip install -q tensorflow==2.11.0\n",
        "# !pip install -q -U \"tensorflow-text==2.11.*\"\n",
        "# !pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len= 128\n",
        "# Tokenize and encode the sentences\n",
        "X_train_encoded = tokenizer.batch_encode_plus(X_train.tolist(),\n",
        "                                              padding=True,\n",
        "                                              truncation=True,\n",
        "                                              max_length = max_len,\n",
        "                                              return_tensors='tf')\n",
        "\n",
        "\n",
        "X_test_encoded = tokenizer.batch_encode_plus(X_test.tolist(),\n",
        "                                              padding=True,\n",
        "                                              truncation=True,\n",
        "                                              max_length = max_len,\n",
        "                                              return_tensors='tf')"
      ],
      "metadata": {
        "id": "sj1gU2NYpa_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsjEJZIgpsSq",
        "outputId": "d949c5b3-3955-4f83-a69e-15bb55e9bb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)#set learning rate schedule\n",
        "\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "metadata": {
        "id": "QGn_2ertqDu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train the model\n",
        "history = model.fit(\n",
        "    [X_train_encoded['input_ids'], X_train_encoded['token_type_ids'], X_train_encoded['attention_mask']],\n",
        "    y_train,\n",
        "    validation_data=(\n",
        "      [X_test_encoded['input_ids'], X_test_encoded['token_type_ids'], X_test_encoded['attention_mask']],y_test),\n",
        "    batch_size=50,\n",
        "    epochs = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMwaR6HmqFi4",
        "outputId": "c09af578-f6d8-4c0a-ec0b-c554f8fcb869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "480/480 [==============================] - 675s 1s/step - loss: 0.3312 - accuracy: 0.8518 - val_loss: 0.2675 - val_accuracy: 0.8845\n",
            "Epoch 2/2\n",
            "480/480 [==============================] - 677s 1s/step - loss: 0.1914 - accuracy: 0.9250 - val_loss: 0.2717 - val_accuracy: 0.8958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict([X_test_encoded['input_ids'], X_test_encoded['token_type_ids'], X_test_encoded['attention_mask']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcxwf4u_v1bs",
        "outputId": "86d2f856-b75c-4621-dc7a-ddd82a830130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 55s 272ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = y_hat.logits\n",
        "y_hat = tf.argmax(logits, axis=1)\n",
        "y_hat = y_hat.numpy()"
      ],
      "metadata": {
        "id": "4xTFNdIyv6tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print()\n",
        "print(classification_report(y_test, y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyXadwTtz11Y",
        "outputId": "86f64016-e173-467b-dc30-a74d4e542fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.87      0.89      3033\n",
            "           1       0.88      0.92      0.90      2967\n",
            "\n",
            "    accuracy                           0.90      6000\n",
            "   macro avg       0.90      0.90      0.90      6000\n",
            "weighted avg       0.90      0.90      0.90      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8csyuxzwTcM",
        "outputId": "920d63e9-2c52-48b7-ebbe-cf631df758fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "XOPl1kzczdT7",
        "outputId": "8e5d014f-e9ad-441c-8008-b4de3c31a35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41027    0\n",
              "13358    0\n",
              "29091    1\n",
              "45170    0\n",
              "3606     1\n",
              "        ..\n",
              "9891     1\n",
              "38931    0\n",
              "2292     1\n",
              "13638    1\n",
              "33199    1\n",
              "Name: sentiment, Length: 6000, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41027</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13358</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29091</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45170</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3606</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9891</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38931</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2292</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13638</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33199</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows  1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join('/content', 'my_model')\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "hikOwY6RwOn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r my_model.zip my_model"
      ],
      "metadata": {
        "id": "g18p9mzyVEoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7728d807-6b5f-4b58-d2b3-f85b43ae000e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: my_model/ (stored 0%)\n",
            "  adding: my_model/fingerprint.pb (stored 0%)\n",
            "  adding: my_model/saved_model.pb (deflated 92%)\n",
            "  adding: my_model/variables/ (stored 0%)\n",
            "  adding: my_model/variables/variables.data-00000-of-00001 (deflated 11%)\n",
            "  adding: my_model/variables/variables.index (deflated 79%)\n",
            "  adding: my_model/assets/ (stored 0%)\n",
            "  adding: my_model/keras_metadata.pb (deflated 95%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r my_zipped_bert_model.zip my_bert_model\n",
        "#!zip error_handler.zip error_handler.pkl  # Optional, if you saved the error handler separately"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxLqFtR-xrVw",
        "outputId": "34fec8d0-d4bf-4ce2-b9ca-0e2901ae4b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: my_bert_model/ (stored 0%)\n",
            "  adding: my_bert_model/tf_model.h5 (deflated 8%)\n",
            "  adding: my_bert_model/config.json (deflated 47%)\n",
            "  adding: error_handler.pkl (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Save the model to your Drive\n",
        "# model_path = '/content/drive/MyDrive/my_model'\n",
        "# model.save(model_path) # or model.save_pretrained(model_path) for BERT"
      ],
      "metadata": {
        "id": "D0fIJIG4TKn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = 0;\n",
        "x +=1;"
      ],
      "metadata": {
        "id": "Ye5C1-hRTd02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "NV-CqSl9nOOP",
        "outputId": "fe73137f-a43d-42e2-97a8-6f9212de80ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.series.Series</b><br/>def __init__(data=None, index=None, dtype: Dtype | None=None, name=None, copy: bool | None=None, fastpath: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/series.py</a>One-dimensional ndarray with axis labels (including time series).\n",
              "\n",
              "Labels need not be unique but must be a hashable type. The object\n",
              "supports both integer- and label-based indexing and provides a host of\n",
              "methods for performing operations involving the index. Statistical\n",
              "methods from ndarray have been overridden to automatically exclude\n",
              "missing data (currently represented as NaN).\n",
              "\n",
              "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
              "associated index values-- they need not be the same length. The result\n",
              "index will be the sorted union of the two indexes.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : array-like, Iterable, dict, or scalar value\n",
              "    Contains data stored in Series. If data is a dict, argument order is\n",
              "    maintained.\n",
              "index : array-like or Index (1d)\n",
              "    Values must be hashable and have the same length as `data`.\n",
              "    Non-unique index values are allowed. Will default to\n",
              "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
              "    and index is None, then the keys in the data are used as the index. If the\n",
              "    index is not None, the resulting Series is reindexed with the index values.\n",
              "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
              "    Data type for the output Series. If not specified, this will be\n",
              "    inferred from `data`.\n",
              "    See the :ref:`user guide &lt;basics.dtypes&gt;` for more usages.\n",
              "name : Hashable, default None\n",
              "    The name to give to the Series.\n",
              "copy : bool, default False\n",
              "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.series&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing Series from a dictionary with an Index specified\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "a   1\n",
              "b   2\n",
              "c   3\n",
              "dtype: int64\n",
              "\n",
              "The keys of the dictionary match with the Index values, hence the Index\n",
              "values have no effect.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "x   NaN\n",
              "y   NaN\n",
              "z   NaN\n",
              "dtype: float64\n",
              "\n",
              "Note that the Index is first build with the keys from the dictionary.\n",
              "After this the Series is reindexed with the given Index values, hence we\n",
              "get all NaN as a result.\n",
              "\n",
              "Constructing Series from a list with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = [1, 2]\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "[1, 2]\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `copy` of\n",
              "the original data even though `copy=False`, so\n",
              "the data is unchanged.\n",
              "\n",
              "Constructing Series from a 1d ndarray with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = np.array([1, 2])\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "array([999,   2])\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `view` on\n",
              "the original data, so\n",
              "the data is changed as well.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 245);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to save a numpy array\n",
        "\n",
        "import numpy as np\n",
        "np.save('y_hat', y_hat)\n"
      ],
      "metadata": {
        "id": "xYVfVyc9nbmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"y_test\", np.array(y_test))"
      ],
      "metadata": {
        "id": "slISgdnIn1bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: convert np array to pandas dataframe\n",
        "\n",
        "import pandas as pd\n",
        "y_hat_df = pd.DataFrame(y_hat)\n",
        "y_test_df = pd.DataFrame(y_test)\n"
      ],
      "metadata": {
        "id": "wqtpbR8sn-ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0;\n",
        "incorrect = 0;\n",
        "for i in range(len(y_hat)):\n",
        "  if y_hat[i] == np.array(y_test_df)[i]:\n",
        "    print(\"correct\");\n",
        "    correct += 1;\n",
        "  else:\n",
        "    print(\"incorrect\")\n",
        "    incorrect += 1;\n",
        "print(\"correct: \", correct)\n",
        "print(\"incorrect: \", incorrect)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYuqyulcoJrm",
        "outputId": "ef1be8ea-b581-43b9-ec5b-70476d61be27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "incorrect\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct\n",
            "correct:  5375\n",
            "incorrect:  625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = 0;"
      ],
      "metadata": {
        "id": "oQmB2wx-oSlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC4gr3vY-_ti"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import os\n",
        "\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import tensorflow_models as tfm\n",
        "# import tensorflow_hub as hub\n",
        "# import tensorflow_datasets as tfds\n",
        "# tfds.disable_progress_bar()\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Reshape, Dropout, BatchNormalization, Activation\n",
        "# from tensorflow.keras.layers import MaxPooling2D\n",
        "# from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
        "# from tensorflow.keras.layers import LeakyReLU\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# import os\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# from transformers import AutoTokenizer, TFBertModel\n",
        "# from transformers import TrainingArguments, Trainer, BertTokenizer, BertForSequenceClassification;\n",
        "# #neural network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_clean = preproc(df, 'Input')\n",
        "# df_clean.drop('index', axis=1, inplace=True)\n",
        "# df_clean['num_words'] = df_clean['Input'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# df_clean['Sentiment'] = df_clean['Sentiment'].cat.codes\n",
        "# encoded_dict = {'anger':0, 'fear':1, 'joy':2, 'love':3, 'sadness':4, 'surprise':5}\n"
      ],
      "metadata": {
        "id": "N8HBWev0Y1HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "# bert = TFBertModel.from_pretrained('bert-base-cased')\n",
        "# max_len = 128;"
      ],
      "metadata": {
        "id": "--PEKncGhjgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = tokenizer(text = X_train.tolist(), add_special_tokens = True, max_length = max_len, truncation = True, padding = True, return_tensors = \"tf\", return_token_type_ids =False, return_attention_mask = True, verbose = True)\n",
        "# X_test = tokenizer(text = X_test.tolist(), add_special_tokens = True, max_length = max_len, truncation = True, padding = True, return_tensors = \"tf\", return_token_type_ids =False, return_attention_mask = True, verbose = True)"
      ],
      "metadata": {
        "id": "znikqXNXhrAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train"
      ],
      "metadata": {
        "id": "qIyQ4Zj9Io4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class BertInputProcessor(tf.keras.layers.Layer):\n",
        "#   def __init__(self, tokenizer, packer):\n",
        "#     super().__init__()\n",
        "#     self.tokenizer = tokenizer\n",
        "#     self.packer = packer\n",
        "\n",
        "#   def call(self, inputs):\n",
        "#     tok1 = self.tokenizer(inputs['sentence1'])#sentence 1 and 2 are the freature. GLUE is tring to see if the sentence 1 and 2 meant the same or not\n",
        "#     tok2 = self.tokenizer(inputs['sentence2'])\n",
        "\n",
        "#     packed = self.packer([tok1, tok2])\n",
        "\n",
        "#     if 'label' in inputs:\n",
        "#       return packed, inputs['label']\n",
        "#     else:\n",
        "#       return packed"
      ],
      "metadata": {
        "id": "jQDHTZToGNH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras.initializers import TruncatedNormal\n",
        "# from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "# from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from tensorflow.keras.layers import Input, Dense, Layer;\n",
        "\n",
        "# # Use a smaller batch size to reduce memory usage\n",
        "# batch_size = 16\n",
        "\n",
        "# # Create TensorFlow Dataset objects for efficient batching and prefetching\n",
        "# train_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids':X_train['input_ids'], 'attention_mask':X_train['attention_mask']},\n",
        "#                                                    to_categorical(df_train['Sentiment'])))\n",
        "# train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids':X_test['input_ids'], 'attention_mask':X_test['attention_mask']},\n",
        "#                                                   to_categorical(df_test['Sentiment'])))\n",
        "# test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# embeddings = bert(X_train[\"input_ids\"], attention_mask = X_train[\"attention_mask\"]) # 0 = last hidden state, 1 = poller_output\n",
        "# out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "# out = Dense(32, activation='relu')(out)\n",
        "# out = tf.keras.layers.Dropout(0.1)(out)\n",
        "# out = Dense(8, activation='relu')(out)\n",
        "\n",
        "# y = Dense(6, activation='softmax')(out)\n",
        "\n",
        "# model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)[0]\n",
        "# model.layers[2].trainable = True\n",
        "\n",
        "# optimizer = Adam(\n",
        "#     learning_rate=5e-05, # HF recommendation\n",
        "#     epsilon=1e-08,\n",
        "#     decay=0.01,\n",
        "#     clipnorm=1.0\n",
        "# )\n",
        "\n",
        "# loss = CategoricalCrossentropy(from_logits=True)\n",
        "# metric = CategoricalAccuracy('balanced_accuracy')\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=optimizer,\n",
        "#     loss=loss,\n",
        "#     metrics=metric\n",
        "# )\n",
        "\n",
        "# history = model.fit(\n",
        "#     x = {'input_ids':X_train['input_ids'], 'attention_mask':X_train['attention_mask']},\n",
        "#     y = to_categorical(df_train['Sentiment']),\n",
        "#     validation_data = ({'input_ids':X_test['input_ids'], 'attention_mask':X_test['attention_mask']},\n",
        "#                         to_categorical(df_test['Sentiment'])),\n",
        "#     epochs=1,\n",
        "#     batch_size=32\n",
        "# )"
      ],
      "metadata": {
        "id": "2UhL-mBNh0Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type(X_train)\n",
        "config = model.config"
      ],
      "metadata": {
        "id": "kXoekqcfk8Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, BertTokenizerFast\n",
        "\n",
        "# Assuming 'model' is your pre-trained BERT model\n",
        "config = model.config\n",
        "\n",
        "# Save the configuration to a JSON file\n",
        "config.save_pretrained('/content/config')\n",
        "\n",
        "# To load the configuration later:\n",
        "loaded_config = BertConfig.from_pretrained('/content/config')"
      ],
      "metadata": {
        "id": "TCcanpOfvW07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install safetensors\n",
        "from safetensors.torch import save_file\n",
        "save_file(model.state_dict(), \"model.safetensors\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "fQatLkpVwjaM",
        "outputId": "a6da95c9-ce8f-438d-8b08-66cf2143516b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TFBertForSequenceClassification' object has no attribute 'state_dict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-985e6046930b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install safetensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msafetensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.safetensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'TFBertForSequenceClassification' object has no attribute 'state_dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "BJ3ZCyuZwwW5",
        "outputId": "985b85bf-1876-4cf6-83b6-3f5e459fa585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification</b><br/>def error_handler(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_tf_bert.py</a>Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled\n",
              "output) e.g. for GLUE tasks.\n",
              "\n",
              "\n",
              "This model inherits from [`TFPreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
              "library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
              "etc.)\n",
              "\n",
              "This model is also a [keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) subclass. Use it\n",
              "as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage and\n",
              "behavior.\n",
              "\n",
              "&lt;Tip&gt;\n",
              "\n",
              "TensorFlow models and layers in `transformers` accept two formats as input:\n",
              "\n",
              "- having all inputs as keyword arguments (like PyTorch models), or\n",
              "- having all inputs as a list, tuple or dict in the first positional argument.\n",
              "\n",
              "The reason the second format is supported is that Keras methods prefer this format when passing inputs to models\n",
              "and layers. Because of this support, when using methods like `model.fit()` things should &quot;just work&quot; for you - just\n",
              "pass your inputs and labels in any format that `model.fit()` supports! If, however, you want to use the second\n",
              "format outside of Keras methods like `fit()` and `predict()`, such as when creating your own layers or models with\n",
              "the Keras `Functional` API, there are three possibilities you can use to gather all the input Tensors in the first\n",
              "positional argument:\n",
              "\n",
              "- a single Tensor with `input_ids` only and nothing else: `model(input_ids)`\n",
              "- a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:\n",
              "`model([input_ids, attention_mask])` or `model([input_ids, attention_mask, token_type_ids])`\n",
              "- a dictionary with one or several input Tensors associated to the input names given in the docstring:\n",
              "`model({&quot;input_ids&quot;: input_ids, &quot;token_type_ids&quot;: token_type_ids})`\n",
              "\n",
              "Note that when creating models and layers with\n",
              "[subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/) then you don&#x27;t need to worry\n",
              "about any of this, as you can just pass inputs like you would to any other Python function!\n",
              "\n",
              "&lt;/Tip&gt;\n",
              "\n",
              "Args:\n",
              "    config ([`BertConfig`]): Model configuration class with all the parameters of the model.\n",
              "        Initializing with a config file does not load the weights associated with the model, only the\n",
              "        configuration. Check out the [`~TFPreTrainedModel.from_pretrained`] method to load the model weights.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1688);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFBertForSequenceClassification, BertConfig\n",
        "\n",
        "# Assuming 'model' is your trained TFBertForSequenceClassification model\n",
        "# ... (Your model definition, training code, and error_handler function) ...\n",
        "\n",
        "# 1. Save the model using save_pretrained\n",
        "model.save_pretrained(\"my_bert_model\")\n",
        "\n",
        "# # 2. (Optional) Save the error handler function separately\n",
        "# import pickle\n",
        "# with open(\"error_handler.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(error_handler, f)\n",
        "\n",
        "# --- Later, to load the model and error handler ---\n",
        "\n",
        "# 1. Load the model\n",
        "loaded_model = TFBertForSequenceClassification.from_pretrained(\"my_bert_model\")\n",
        "\n",
        "# # 2. (Optional) Load the error handler function\n",
        "# with open(\"error_handler.pkl\", \"rb\") as f:\n",
        "#     loaded_error_handler = pickle.load(f)\n",
        "\n",
        "# Now you can use loaded_model and loaded_error_handler as needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvhAx8gTxLS9",
        "outputId": "0fa85903-d9ee-4007-d8e6-2cbf9c3762c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at my_bert_model were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at my_bert_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}